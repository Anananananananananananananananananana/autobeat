{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-17T07:31:02.805917800Z",
     "start_time": "2023-10-17T07:31:02.435026300Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "`MAX_NPS` and `MAX_BPM` filter out the challenge maps which spam notes and thus should have an abnormally high nps or bpm. `MIN_NPS` filters out the slow accuracy maps that may have strange patterns only hittable at low speeds.\n",
    "`MIN_DURATION_SECONDS` and `MAX_DURATION_SECONDS` are to filter out the short maps, low effort maps or the extremely long movie soundtracks that occasionally pop up.\n",
    " `MIN_RATING` and `MIN_UPVOTES` are to make sure the maps are actually well liked by the players.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "START_DATE = '2021-01-01'\n",
    "END_DATE = '2023-10-01'\n",
    "MAX_NPS = 13\n",
    "MIN_NPS = 4\n",
    "MAX_BPM = 350\n",
    "MIN_DURATION_SECONDS = 60\n",
    "MAX_DURATION_SECONDS = 360\n",
    "MIN_RATING = 0.7\n",
    "MIN_UPVOTES = 40"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T05:45:13.952969Z",
     "start_time": "2023-10-17T05:45:13.945108500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Functions to search through and select high quality maps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "# set max_requests to -1 to search until all maps are exhausted\n",
    "def generateDataset(max_requests=1):\n",
    "    end = END_DATE\n",
    "    num_requests = 0\n",
    "    pruned_maps = []\n",
    "    while num_requests != max_requests:\n",
    "        maps_result = requests.get('https://api.beatsaver.com/search/text/0?from=' + START_DATE + '&maxBpm=' + str(MAX_BPM) + '&maxDuration=' + str(MAX_DURATION_SECONDS) + '&maxNps=' + str(MAX_NPS) + '&minDuration=' + str(MIN_DURATION_SECONDS) + '&minNps=' + str(MIN_NPS) + '&minRating=' + str(MIN_RATING) + '&noodle=false&sortOrder=Latest&to=' + end)\n",
    "        num_requests += 1\n",
    "        maps_json = json.loads(maps_result.text)\n",
    "        pruned_maps += pruneMaps(maps_json['docs'])\n",
    "        end = maps_json['docs'][-1]['createdAt']\n",
    "\n",
    "        # Beatsaver sends maps in batches of 20\n",
    "        if len(maps_json['docs']) < 20:\n",
    "            break\n",
    "        print(len(pruned_maps))\n",
    "    return pruned_maps\n",
    "\n",
    "def pruneMaps(maps_json):\n",
    "    pruned_maps = []\n",
    "    for map in maps_json:\n",
    "        # Min Upvotes check\n",
    "        if map['stats']['upvotes'] < MIN_UPVOTES:\n",
    "            continue\n",
    "\n",
    "        beatleader_info = json.loads(requests.get('https://api.beatleader.xyz/leaderboards/hash/'+map['versions'][0]['hash']).text)\n",
    "        time.sleep(0.1) # Precaution to not exceed maximum requests/second\n",
    "\n",
    "        # Check that any Standard difficulty does not require Mapping Extensions, Noodle Extensions, or V3 notes.\n",
    "        for diff in beatleader_info['song']['difficulties']:\n",
    "            if diff['mode'] == 1 and diff['requirements'] & 0b101100 != 0:\n",
    "                break\n",
    "        else:\n",
    "            pruned_maps.append([map['id'], map['versions'][0]['downloadURL']])\n",
    "    return pruned_maps"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T04:30:18.903106300Z",
     "start_time": "2023-10-17T04:30:18.891541700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generating dataset text file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "maps = generateDataset(max_requests=-1)\n",
    "print(len(maps))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "dataset_txt = open('dataset_ids_urls.txt', 'w')\n",
    "dataset_txt.write(json.dumps(maps, indent=4))\n",
    "dataset_txt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T05:35:28.905339300Z",
     "start_time": "2023-10-17T05:35:28.888694600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Functions to download all Standard mode .dat files into `directory`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "directory = 'BeatSaberMapsDataset'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T07:31:31.606747900Z",
     "start_time": "2023-10-17T07:31:31.601731600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def downloadDataset(map_ids_urls):\n",
    "    # Initializing directories and log\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "    os.mkdir(directory)\n",
    "    os.mkdir(directory+'\\\\dlfolder')\n",
    "    for map_id, url in map_ids_urls:\n",
    "        deleteMap()\n",
    "        downloaded = downloadMap(url)\n",
    "        time.sleep(0.1)\n",
    "        if not downloaded:\n",
    "            continue\n",
    "        with open(directory+'\\\\dlfolder\\\\currentMap\\\\info.dat', 'r', encoding='utf-8') as info:\n",
    "            infoJSON = json.load(info)\n",
    "            songBPM = infoJSON['_beatsPerMinute']\n",
    "        print('Extracting map: ', map_id)\n",
    "        extractStandardDiffstoCSV(map_id, songBPM)\n",
    "        deleteMap()\n",
    "    shutil.rmtree(directory+'\\\\dlfolder')\n",
    "\n",
    "def deleteMap():\n",
    "    if os.path.exists(directory+'dlFolder\\\\zipped'):\n",
    "        os.remove(directory+'dlFolder\\\\zipped')\n",
    "    if os.path.exists(directory+'dlFolder\\\\currentMap'):\n",
    "        shutil.rmtree(directory+'dlFolder\\\\currentMap')\n",
    "\n",
    "def downloadMap(url):\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    \n",
    "    with open(directory+'\\\\dlfolder\\\\zipped', 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    \n",
    "    try:\n",
    "        with zipfile.ZipFile(directory+'\\\\dlFolder\\\\zipped', 'r') as zip_ref:\n",
    "            zip_ref.extractall(directory+'\\\\dlFolder\\\\currentMap')\n",
    "            zip_ref.close()\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def extractStandardDiffstoCSV(map_id, songBPM):\n",
    "    leaderboardID_dict = {\n",
    "        'EasyStandard' : '11',\n",
    "        'NormalStandard' : '31',\n",
    "        'HardStandard' : '51',\n",
    "        'ExpertStandard' : '71',\n",
    "        'ExpertPlusStandard' : '91'\n",
    "    }\n",
    "    for key, value in leaderboardID_dict.items():\n",
    "        if os.path.exists(directory+'\\\\dlfolder\\\\currentMap\\\\'+key+'.dat'):\n",
    "            try:\n",
    "                with open(directory+'\\\\dlfolder\\\\currentMap\\\\'+key+'.dat', 'r', encoding='utf-8') as difficulty_dat:\n",
    "                    difficultyJSON = json.load(difficulty_dat)\n",
    "                    \n",
    "                    version = 0\n",
    "                    if 'version' in difficultyJSON:\n",
    "                        version = 3\n",
    "                    elif '_version' in difficultyJSON:\n",
    "                        version = 2\n",
    "                    \n",
    "                    if version == 2:\n",
    "                        # Didn't think I'd need this but some bozo had a lightshow map mislabeled\n",
    "                        if len(difficultyJSON['_notes']) <= 0:\n",
    "                            continue\n",
    "                        \n",
    "                        note_data = pd.DataFrame.from_dict(difficultyJSON['_notes'])\n",
    "                        try:\n",
    "                            if '_customData' in note_data.columns:\n",
    "                                note_data = note_data.drop('_customData', axis=1)\n",
    "                            note_data['_timeInSeconds'] = note_data['_time'].apply(lambda x: x*60/songBPM)\n",
    "                            note_data.to_csv(directory+'\\\\'+map_id+value+'.csv', mode='w')\n",
    "                        except:\n",
    "                            print('Bad CustomData in a v2 file')\n",
    "                            continue\n",
    "                    # V3 difficulty files store bombs and notes separately\n",
    "                    # Also standardize the V3 formats to have the same labels as V2 in the dataset\n",
    "                    elif version == 3:\n",
    "                        \n",
    "                        # Didn't think I'd need this but some bozo had a lightshow map mislabeled\n",
    "                        if len(difficultyJSON['colorNotes']) <= 0:\n",
    "                            continue\n",
    "                        \n",
    "                        notes = pd.DataFrame.from_dict(difficultyJSON['colorNotes'])\n",
    "                        notes = notes.drop('a', axis=1)\n",
    "                        if len(difficultyJSON['bombNotes']) > 0:\n",
    "                            bombs = pd.DataFrame.from_dict(difficultyJSON['bombNotes'])\n",
    "                            bombs['c'] = 3\n",
    "                            bombs['d'] = 8\n",
    "                            note_data = pd.merge(notes, bombs, how=\"outer\", on=['b', 'x', 'y', 'c', 'd'])\n",
    "                            note_data = note_data.sort_values(by=['b'])\n",
    "                            note_data = note_data.reset_index(drop='True')\n",
    "                        else:\n",
    "                            note_data = notes\n",
    "                        note_data = note_data.rename(columns={'b':'_time', 'x':'_lineIndex', 'y':'_lineLayer', 'c':'_type', 'd':'cutDirection'})\n",
    "                        note_data['_timeInSeconds'] = note_data['_time'].apply(lambda x: x*60/songBPM)\n",
    "                        note_data.to_csv(directory+'\\\\'+map_id+value+'.csv', mode='w')\n",
    "            \n",
    "            # yes this is awful code I just didn't want to iterate on a 3 hour problem so I manually deleted any file that threw an error of any kind\n",
    "            except Exception as e:\n",
    "                f = open('log.txt', 'a')\n",
    "                f.write(str(e)+' ')\n",
    "                f.write(map_id+value+'\\n')\n",
    "                f.close()\n",
    "                continue"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T10:35:11.544749700Z",
     "start_time": "2023-10-17T10:35:11.526396400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Downloading dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "dataset_txt = open('dataset_ids_urls.txt', 'r')\n",
    "maps = json.load(dataset_txt)\n",
    "dataset_txt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T07:31:19.697796Z",
     "start_time": "2023-10-17T07:31:19.690965400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(maps))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "downloadDataset(maps)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
